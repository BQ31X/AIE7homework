{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxpWDFG11o3G"
      },
      "source": [
        "# Multi-Agent Workflows + RAG - LangGraph\n",
        "\n",
        "Today we'll be looking at an example of a Multi-Agent workflow that's powered by LangGraph, LCEL, and more!\n",
        "\n",
        "We're going to be, more specifically, looking at a \"heirarchical agent teams\" from the [AutoGen: Enabling Next-Gen LLM\n",
        "Applications via Multi-Agent Conversation](https://arxiv.org/pdf/2308.08155) paper.\n",
        "\n",
        "This will be the final \"graph\" of our system:\n",
        "\n",
        "![image](https://i.imgur.com/Xro0QiR.png)\n",
        "\n",
        "It's important to keep in mind that the actual implementation will be constructed of 3 separate graphs, the final one having 2 graphs as nodes! LangGraph is a heckuva tool!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyzoBrWoYeOZ"
      },
      "source": [
        "# 🤝 BREAKOUT ROOM #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx3oaVoX5cA2"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpv2MWqu5vS9"
      },
      "source": [
        "Since we'll be relying on OpenAI's suite of models to power our agents today, we'll want to provide our OpenAI API Key.\n",
        "\n",
        "We're also going to be using the Tavily search tool - so we'll want to provide that API key as well!\n",
        "\n",
        "Instruction for how to obtain the Tavily API key can be found:\n",
        "\n",
        "1. [Tavily API Key](https://app.tavily.com/sign-in)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h30OjkLfeR2Y",
        "outputId": "f75bb26e-b89d-4611-c29b-f339b3e868af"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_LD7rwT6PbO"
      },
      "source": [
        "## Task 1: Simple LangGraph RAG\n",
        "\n",
        "Now that we have our dependencies set-up - let's create a simple RAG graph that works over our Loan PDFs from previous sessions.\n",
        "\n",
        "> NOTE: While this particular example is very straight forward - you can \"plug in\" any complexity of chain you desire as a node in a LangGraph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY7T5kxJ6jGn"
      },
      "source": [
        "## Retrieval\n",
        "\n",
        "The 'R' in 'RAG' - this is, at this point, fairly straightforward!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGuPxSCk7Ztz"
      },
      "source": [
        "#### Data Collection and Processing\n",
        "\n",
        "A classic first step, at this point, let's grab our desired document!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LfuoEYRCln3H"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "directory_loader = DirectoryLoader(\"data\", glob=\"**/*.pdf\", loader_cls=PyMuPDFLoader)\n",
        "\n",
        "loan_knowledge_resources = directory_loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_t_F1zG6vXa"
      },
      "source": [
        "Now we can chunk it down to size!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5R7A_z8CgL79"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def tiktoken_len(text):\n",
        "    tokens = tiktoken.encoding_for_model(\"gpt-4o\").encode(\n",
        "        text,\n",
        "    )\n",
        "    return len(tokens)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 750,\n",
        "    chunk_overlap = 0,\n",
        "    length_function = tiktoken_len,\n",
        ")\n",
        "\n",
        "loan_knowledge_chunks = text_splitter.split_documents(loan_knowledge_resources)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGE-VuMc7AKv"
      },
      "source": [
        "Now we've successfully split our single PDF into..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgYBHsdWmLvW",
        "outputId": "aa9a830e-f7db-4bb3-f542-c0614cb01aca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "375"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(loan_knowledge_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxaKmmyh7DHD"
      },
      "source": [
        "documents!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGWs7KTd7QPS"
      },
      "source": [
        "#### Embedding Model and Vector Store\n",
        "\n",
        "Now that we have our chunked document - lets create a vector store, which will first require us to create an embedding model to get the vector representations of our text!\n",
        "\n",
        "We'll use OpenAI's [`text-embedding-3-small`](https://platform.openai.com/docs/guides/embeddings/embedding-models) model - as it's cheap, and performant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xLIWMMZCmfrj"
      },
      "outputs": [],
      "source": [
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTEi7Ww573sc"
      },
      "source": [
        "Now we can create our QDrant backed vector store!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xct51f8omVAU"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "qdrant_vectorstore = Qdrant.from_documents(\n",
        "    documents=loan_knowledge_chunks,\n",
        "    embedding=embedding_model,\n",
        "    location=\":memory:\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzGq6o4s79Ar"
      },
      "source": [
        "Let's make sure we can access it as a retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OTnQZbWymi4K"
      },
      "outputs": [],
      "source": [
        "qdrant_retriever = qdrant_vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU8qSrMS7_D7"
      },
      "source": [
        "### Augmented\n",
        "\n",
        "Now that we have our retrieval process set-up, we need to set up our \"augmentation\" process - AKA a prompt template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lezTN0zCmk46"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "HUMAN_TEMPLATE = \"\"\"\n",
        "#CONTEXT:\n",
        "{context}\n",
        "\n",
        "QUERY:\n",
        "{query}\n",
        "\n",
        "Use the provide context to answer the provided user query. Only use the provided context to answer the query. If you do not know the answer, or it's not contained in the provided context respond with \"I don't know\"\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", HUMAN_TEMPLATE)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9fa63nM7IKK"
      },
      "source": [
        "### Generation\n",
        "\n",
        "Last, but certainly not least, let's put the 'G' in 'RAG' by adding our generator - in this case, we can rely on OpenAI's [`gpt-4o-mini`](https://platform.openai.com/docs/models/gpt-4o-mini) model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AwEi29-Jo3a8"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO-ZC0T98XJJ"
      },
      "source": [
        "### RAG - Retrieval Augmented Generation\n",
        "\n",
        "All that's left to do is combine our R, A, and G into a single graph - and we're off!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Study notes\n",
        "From ChatGPT, to help me visualize next block\n",
        "| Name              | Kind of Thing         | Purpose                                    |\n",
        "| ----------------- | --------------------- | ------------------------------------------ |\n",
        "| `StateGraph`      | Class                 | Defines and builds a LangGraph flow        |\n",
        "| `Document`        | Class                 | Wraps text + metadata                      |\n",
        "| `StrOutputParser` | Class (utility)       | Converts LLM output into string            |\n",
        "| `TypedDict`       | Metaclass (for types) | Lets you define structured dict type hints |\n",
        "\n",
        "_____\n",
        "\n",
        "| Key        | Type             | Purpose                          |\n",
        "| ---------- | ---------------- | -------------------------------- |\n",
        "| `question` | `str`            | User’s original input or query   |\n",
        "| `context`  | `list[Document]` | Retrieved docs from vector store |\n",
        "| `response` | `str`            | Final generated answer           |\n",
        "_____\n",
        "| Step                | What it does                               |\n",
        "| ------------------- | ------------------------------------------ |\n",
        "| `Chat_Prompt`       | Formats the input into a structured prompt |\n",
        "| `openai_chat_model` | Sends the prompt to the OpenAI chat model  |\n",
        "| `StrOutputParser()` | Takes raw LLM output and returns a `str`   |\n",
        "\n",
        "______________\n",
        "\n",
        "| Action                | Effect                                           |\n",
        "| --------------------- | ------------------------------------------------ |\n",
        "| `StateGraph(State)`   | Declares the graph and the shape of shared state |\n",
        "| `add_sequence([...])` | Adds steps **and wires** them in order           |\n",
        "| Start/end nodes       | Auto-wired by `add_sequence()`                   |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nlOJrPm_oT3S"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "class State(TypedDict):\n",
        "  question: str\n",
        "  context: list[Document]\n",
        "  response: str\n",
        "\n",
        "def retrieve(state: State) -> State:\n",
        "  retrieved_docs = qdrant_retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}\n",
        "\n",
        "def generate(state: State) -> State:\n",
        "  generator_chain = chat_prompt | openai_chat_model | StrOutputParser()\n",
        "  response = generator_chain.invoke({\"query\" : state[\"question\"], \"context\" : state[\"context\"]})\n",
        "  return {\"response\" : response}\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder = graph_builder.add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "rag_graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x12345d7d0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiWrbXpu8ggz"
      },
      "source": [
        "Let's test this out and make sure it works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "gJhFlW32pBPe",
        "outputId": "7aee04b6-608f-4639-adca-66225d4d3002"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is the maximum loan amount?',\n",
              " 'context': [Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 69, '_id': '712c8c4e07ce4bd69c6e5b1d168bf076', '_collection_name': '452ec84e42ee43cf835dbbb2eeaf7bcc'}, page_content='program. Therefore, the maximum loan amount the student may receive for the program at School B (for the\\nabbreviated loan period and any subsequent loan period combined) is a total of $1,815, not more than $1,155 of\\nwhich may be subsidized (the prorated loan limits for the program). If the student receives the maximum prorated\\nloan limit for the program during the abbreviated loan period, there is no remaining loan eligibility for the\\nprogram following the completion of the abbreviated loan period.'),\n",
              "  Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 39, '_id': 'd559e3ca9b004336a86b754ca4645318', '_collection_name': '452ec84e42ee43cf835dbbb2eeaf7bcc'}, page_content='Volume 8, Chapter 4, Table 4: Aggregate Limits for Direct Subsidized Loans and Direct Unsubsidized Loans\\nTotal (Subsidized and\\nUnsubsidized)\\nMaximum\\nSubsidized\\nDependent undergraduates (excluding those whose parents can9t get\\nDirect PLUS Loans)\\n$31,000\\n$23,000\\nIndependent undergraduates (and dependent undergraduates whose\\nparents can9t get Direct PLUS Loans)\\n$57,500\\n$23,000\\nGraduate and professional students\\n$138,500\\n$65,500\\nNotes on the aggregate loan limits shown in Table 4:\\nThe <Total (Subsidized and Unsubsidized)= column shows the maximum combined outstanding subsidized and\\nunsubsidized loan debt for a student. The <Maximum Subsidized= column shows the maximum portion of the\\ncombined subsidized and unsubsidized limit that may be subsidized. For example, a dependent undergraduate may\\nhave up to a maximum of $31,000 in combined subsidized and unsubsidized outstanding loan debt, but no more\\nthan $23,000 of this amount may consist of subsidized loans.\\nCapitalized interest (unpaid accrued interest that has been added to the principal balance of a loan) is not counted\\ntoward a borrower9s aggregate loan limits (see \"Checking Remaining Loan Eligibility Under Aggregate Loan Limits=\\nbelow for more information).\\nThe $138,500 combined subsidized and unsubsidized aggregate loan limit for graduate and professional students\\nincludes loans received for undergraduate study.\\nThe $65,500 subsidized aggregate loan limit for graduate and professional students includes subsidized loans\\nreceived for prior undergraduate study. It also includes any subsidized loans received for prior graduate or\\nprofessional study before July 1, 2012, when graduate and professional students were eligible to receive subsidized\\nloans (subsidized loan eligibility for graduate and professional students was eliminated effective for loan periods\\nbeginning on or after July 1, 2012).\\nThe loan amounts counted toward a borrower9s aggregate loan limits include any outstanding Direct Subsidized Loan\\nand Direct Unsubsidized Loan amounts, and also any outstanding Subsidized and Unsubsidized Federal Stafford\\nLoans previously borrowed under the FFEL Program (no new loans have been made under the FFEL Program since\\nJune 30, 2010).\\nIf a borrower has a Direct Consolidation Loan or a Federal Consolidation Loan (a consolidation loan made under the\\nFFEL Program), the outstanding amount of the consolidation loan representing any Direct Subsidized Loans, Direct\\nUnsubsidized Loans, Subsidized Federal Stafford Loans, or Unsubsidized Federal Stafford Loans that were paid off by\\nthe consolidation loan is counted toward the borrower9s aggregate subsidized and unsubsidized loan limits\\naccordingly.\\nAggregate Loan Limit for an Undergraduate Student With a Graduate Degree\\nAggregate Loan Limits\\n34 CFR 685.203(d), (e)'),\n",
              "  Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 67, '_id': 'ea3790c2b8ab48a68d0b14d3dd5d4dce', '_collection_name': '452ec84e42ee43cf835dbbb2eeaf7bcc'}, page_content='Generally, the maximum loan amount that the student can receive for the abbreviated loan period is the difference\\nbetween the full annual loan limit applicable to the student at the new school and the loan amount that was\\ndisbursed at the prior school during the overlapping academic year (see the preceding discussion for an exception to\\nthis general rule).\\nThe first disbursement of the loan for the abbreviated loan period at the new school is made at the beginning of the\\nabbreviated loan period. Unless the school qualifies based on its cohort default rate for the exemption from the\\nmultiple disbursement requirement (see Volume 3, Chapter 1), the loan must be disbursed in at least two'),\n",
              "  Document(metadata={'producer': 'GPL Ghostscript 10.00.0', 'creator': 'wkhtmltopdf 0.12.6', 'creationdate': \"D:20250605165703Z00'00'\", 'source': 'data/The_Direct_Loan_Program.pdf', 'file_path': 'data/The_Direct_Loan_Program.pdf', 'total_pages': 71, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20250605165703Z00'00'\", 'trapped': '', 'modDate': \"D:20250605165703Z00'00'\", 'creationDate': \"D:20250605165703Z00'00'\", 'page': 41, '_id': '37f32d2c8e2440e3a2fbef7a74f2a895', '_collection_name': '452ec84e42ee43cf835dbbb2eeaf7bcc'}, page_content='teacher certification and preparatory coursework and the applicable annual loan limits.)\\nHigher Aggregate Loan Limit for Certain Health Professions Students\\nAs explained earlier in this chapter, graduate and professional students who are enrolled in certain health professions\\nprograms are eligible for higher annual Direct Unsubsidized Loan limits. These students also have a higher combined\\nsubsidized and unsubsidized aggregate loan limit.\\nThe combined subsidized and unsubsidized aggregate loan limit for graduate and professional health professions students\\nwho are eligible to receive the increased annual unsubsidized amounts is $224,000. Not more than $65,500 of this\\namount may be from subsidized loans (see the notes following Table 4 above regarding the $65,500 subsidized aggregate\\nloan limit for graduate and professional students).\\nIf a student who received increased Direct Unsubsidized Loan amounts for a qualifying health profession program later\\nenrolls in a non-health professions program, the student is no longer eligible for the increased Direct Unsubsidized Loan\\nlimits. However, the additional loan amounts received for the health professions program are not counted toward the\\nnormal aggregate loan limit for that student.\\nChecking Remaining Eligibility Under the Aggregate Loan Limits\\nBefore originating a Direct Subsidized Loan or Direct Unsubsidized Loan, it9s important to make sure the student still has\\nremaining eligibility under the aggregate loan limits. As long as there is no conflicting information, you may rely on the\\nfinancial aid history (provided on the ISIR as well as on the NSLDS Professional Access website) and the Transfer Student\\nMonitoring process (for transfer students only) to tell you if a student is about to exceed the applicable aggregate loan\\nlimit. (See Volume 1, Chapter 3 for more detail on NSLDS financial aid history, which may also affect eligibility for other\\nTitle IV programs.)\\nThe Loan History in NSLDS for a borrower who has received Title IV loans shows Aggregate Loan Information for the\\nborrower9s outstanding subsidized and unsubsidized loans. The Subsidized and Unsubsidized Aggregate Outstanding\\nPrincipal Balance amounts shown for a borrower in NSLDS do not include unpaid accrued interest, capitalized interest\\n(unpaid interest that has been added to the principal balance of the loan), or other charges, as these amounts are not\\ncounted against the aggregate loan limits.\\nFor each individual loan that a borrower has received, NSLDS shows both the Outstanding Principal Balance (OPB) and the\\nAggregate Outstanding Principal Balance (Agg. OPB). The OPB is what the borrower owes, which may include capitalized\\ninterest and other charges. The Agg. OPB is the portion of the OPB that counts against the aggregate loan limits for\\nsubsidized and unsubsidized loans.\\nFor instance, suppose a student has a Direct Unsubsidized Loan disbursed in the amount of $5,000. Over time, $200 in\\ninterest accrues and is capitalized. Assuming that the borrower has made no payments on the loan, the OPB on the loan\\nwill be $5,200 (this is the amount the borrower owes), and the Agg. OPB will be $5,000 (this is the amount that is counted\\nagainst the aggregate loan limit). If you are looking at information in NSLDS for individual loans, it is the Agg. OPB that\\nyou should use to determine the student9s remaining loan eligibility under the applicable aggregate loan limit.\\nThe Subsidized and Unsubsidized Aggregate Outstanding Principal Balance amounts displayed in NSLDS for a borrower')],\n",
              " 'response': 'Based on the provided context, the maximum loan amount the student may receive for the program at School B (for the abbreviated loan period and any subsequent loan period combined) is a total of $1,815, with no more than $1,155 of this amount being subsidized.'}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_graph.invoke({\"question\" : \"What is the maximum loan amount?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gReMizYk8qd-"
      },
      "source": [
        "### RAG Limitation\n",
        "\n",
        "Notice how we're hard-coding our data, while this is simply meant to be an illustrative example - you could easily extend this to work with any provied paper or document in order to have a more dynamic system.\n",
        "\n",
        "For now, we'll stick with this single hard-coded example in order to keep complexity down in an already very long notebook!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxkbuir-H5rE"
      },
      "source": [
        "##### 🏗️ Activity #1 (Bonus Marks)\n",
        "\n",
        "Allow the system to dynamically fetch Arxiv papers instead of hard coding them.\n",
        "\n",
        "> HINT: Tuesday's assignment will be very useful here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U6a_pqQ9uWf"
      },
      "source": [
        "## Task 2: Helper Functions for Agent Graphs\n",
        "\n",
        "We'll be using a number of agents, nodes, and supervisors in the rest of the notebook - and so it will help to have a collection of useful helper functions that we can leverage to make our lives easier going forward.\n",
        "\n",
        "Let's start with the most simple one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDUnpEEl-L_F"
      },
      "source": [
        "#### Import Wall\n",
        "\n",
        "Here's a wall of imports we'll be needing going forward!\n",
        "\n",
        "#### Study notes\n",
        "| **Import**                                                  | **Purpose**                                                                           |\n",
        "| ----------------------------------------------------------- | ------------------------------------------------------------------------------------- |\n",
        "| `Any`, `Callable`, `List`, `Optional`, `TypedDict`, `Union` | Type hints from `typing`; used to describe data shapes and flexibility                |\n",
        "| `AgentExecutor`, `create_openai_functions_agent`            | From `langchain.agents`; builds and runs OpenAI function-calling agents               |\n",
        "| `JsonOutputFunctionsParser`                                 | Parses OpenAI function-call outputs into structured JSON                              |\n",
        "| `ChatPromptTemplate`, `MessagesPlaceholder`                 | Define structured prompts for chat models, with support for dynamic message insertion |\n",
        "| `AIMessage`, `BaseMessage`, `HumanMessage`                  | Standard message classes used to represent chat turns (e.g. user vs assistant)        |\n",
        "| `Runnable`                                                  | Base interface for anything chainable (LLMs, functions, entire chains)                |\n",
        "| `BaseTool`                                                  | Base class for LangChain tools (functions with metadata)                              |\n",
        "| `ChatOpenAI`                                                | Wrapper around OpenAI chat models (like GPT-4) for LangChain                          |\n",
        "| `END`, `StateGraph`                                         | From LangGraph; used to define the graph and signal termination points                |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TbzoL3Q3-SG1"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Callable, List, Optional, TypedDict, Union\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_core.runnables import Runnable\n",
        "from langchain_core.tools import BaseTool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langgraph.graph import END, StateGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb6Z3EEz-Asi"
      },
      "source": [
        "### Agent Node Helper\n",
        "\n",
        "Since we're going to be wrapping each of our agents into a node - it will help to have an easy way to create the node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5IF7KWfS-JKd"
      },
      "outputs": [],
      "source": [
        "def agent_node(state, agent, name):\n",
        "    result = agent.invoke(state)\n",
        "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwND2teK-WHm"
      },
      "source": [
        "### Agent Creation Helper Function\n",
        "\n",
        "Since we know we'll need to create agents to populate our agent nodes, let's use a helper function for that as well!\n",
        "\n",
        "Notice a few things:\n",
        "\n",
        "1. We have a standard suffix to append to our system messages for each agent to handle the tool calling and boilerplate prompting.\n",
        "2. Each agent has its our scratchpad.\n",
        "3. We're relying on OpenAI's function-calling API for tool selection\n",
        "4. Each agent is its own executor.\n",
        "\n",
        "#### Note: Small typo in line 2. Presumably should be 'its own scratchpad'. Thanks.\n",
        "\n",
        "#### Study notes:\n",
        "How the function calling is used in each assignment\n",
        "\n",
        "| Feature                 | Assignment #5                                | Assignment #6                                      |\n",
        "| ----------------------- | -------------------------------------------- | -------------------------------------------------- |\n",
        "| **Graph**               | No graph — single-agent tool-using loop      | Yes — multi-agent flow using LangGraph             |\n",
        "| **Agent**               | One OpenAI Functions agent                   | Multiple agents (same interface, different roles)  |\n",
        "| **Tools**               | User-defined tools (e.g. math, search)       | May include tools, but focus is on chaining agents |\n",
        "| **Scratchpad / memory** | Tools used mid-turn, with intermediate steps | Messages passed across agents                      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Study Notes\n",
        "Key notes from the class video of the Wiz:\n",
        ">This is the: “Fabled create agent helper function”\n",
        ">“Instead of creating custom agent from a graph, use some boiler plate.”\n",
        "\n",
        ">This function creates each of the agents we need.\n",
        "\n",
        ">Each agent can pass messages and maintain interim state (via  a ’scratchpad’)\n",
        "\n",
        ">(The last line essentially abstracts all the work we did manually in session 5.)\n",
        "\n",
        ">It automatically creates a runnable  agent, which we plug into graph.\n",
        "\n",
        "I’m going to take all that at face value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NxLyHJt5-eUx"
      },
      "outputs": [],
      "source": [
        "def create_agent(\n",
        "    llm: ChatOpenAI,\n",
        "    tools: list,\n",
        "    system_prompt: str,\n",
        ") -> str:\n",
        "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
        "    system_prompt += (\"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
        "    \" Do not ask for clarification.\"\n",
        "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
        "    \" You are chosen for a reason!\")\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                system_prompt,\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "        ]\n",
        "    )\n",
        "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "    executor = AgentExecutor(agent=agent, tools=tools)\n",
        "    return executor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6kmlR9d-1K5"
      },
      "source": [
        "### Supervisor Helper Function\n",
        "\n",
        "Finally, we need a \"supervisor\" that decides and routes tasks to specific agents.\n",
        "\n",
        "Since each \"team\" will have a collection of potential agents - this \"supervisor\" will act as an \"intelligent\" router to make sure that the right agent is selected for the right task.\n",
        "\n",
        "Notice that, at the end of the day, this \"supervisor\" is simply directing who acts next - or if the state is considered \"done\".\n",
        "\n",
        "#### Study notes\n",
        "This is clearly and important block of code. \n",
        "Bottom line: it defines the behaviour of the supervisor agent, telling it how to interact with other agents and how to decide 'who goes next' or whether to finish.\n",
        "Beyond that, the details are somewhat over my head.\n",
        "I reviewed the video, some notes from what Wiz said:\n",
        "\n",
        ">“Favorite block of code”\n",
        ">LLM doesn’t call function or execute code. It is a function definition for the benefit of the LLM.\n",
        ">“This is what we show to the LLM to get it to produce a [json] payload that can be used to call a function” \n",
        "\n",
        "or more specfically (according to Chat GPT): \n",
        ">\"The LLM is “pretending to call a function” — and that function’s purpose is to decide which agent should act next.\"\n",
        "\n",
        "I went through some more details with ChatGPT, but that last line is my main takeaway!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "S2MXA83mrYE2"
      },
      "outputs": [],
      "source": [
        "def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:\n",
        "    \"\"\"An LLM-based router.\"\"\"\n",
        "    options = [\"FINISH\"] + members\n",
        "    function_def = {\n",
        "        \"name\": \"route\",\n",
        "        \"description\": \"Select the next role.\",\n",
        "        \"parameters\": {\n",
        "            \"title\": \"routeSchema\",\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"next\": {\n",
        "                    \"title\": \"Next\",\n",
        "                    \"anyOf\": [\n",
        "                        {\"enum\": options},\n",
        "                    ],\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"next\"],\n",
        "        },\n",
        "    }\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "            (\n",
        "                \"system\",\n",
        "                \"Given the conversation above, who should act next?\"\n",
        "                \" Or should we FINISH? Select one of: {options}\",\n",
        "            ),\n",
        "        ]\n",
        "    ).partial(options=str(options), team_members=\", \".join(members))\n",
        "    return (\n",
        "        prompt\n",
        "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
        "        | JsonOutputFunctionsParser()\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd0zfyq48jKb"
      },
      "source": [
        "## Task 3: Research Team - A LangGraph for Researching Loan Policy\n",
        "\n",
        "Now that we have our RAG chain set-up and some awesome helper functions, we want to create a LangGraph related to researching a specific topic, in this case: Loans!\n",
        "\n",
        "We're going to start by equipping our Research Team with a few tools:\n",
        "\n",
        "1. Tavily Search - aka \"Google\", for the most up to date information possible.\n",
        "2. Our RAG chain - specific and high quality information about our topic.\n",
        "\n",
        "Let's create those tools now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNsVTZrH_alw"
      },
      "source": [
        "### Tool Creation\n",
        "\n",
        "As you can see below, some tools already come pre-packaged ready to use!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ce7FKTZDgAWG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/xc/ddmjsd0x4sl7n58bhfwn6dv00000gn/T/ipykernel_73358/1911882425.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tavily_tool = TavilySearchResults(max_results=5)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIR7cbTL9agM"
      },
      "source": [
        "Creating a custom tool, however, is very straightforward.\n",
        "\n",
        "> NOTE: You *must* include a docstring, as that is what the LLM will consider when deciding when to use this tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sSwO2L_UqFhm"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, List, Tuple, Union\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def retrieve_information(\n",
        "    query: Annotated[str, \"query to ask the retrieve information tool\"]\n",
        "    ):\n",
        "  \"\"\"Use Retrieval Augmented Generation to retrieve information about student loan policies\"\"\"\n",
        "  return rag_graph.invoke({\"question\" : query})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxsMnqjpBTCj"
      },
      "source": [
        "> NOTE: We could just as easily use the LCEL chain directly, since nodes can be LCEL objects - but creating a tool helps explain the tool creation process at the same time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDHCajO4_gB2"
      },
      "source": [
        "### Research Team State\n",
        "\n",
        "Since we're using LangGraph - we're going to need state!\n",
        "\n",
        "Let's look at how we've created our state below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mXminK9d_1fa"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import operator\n",
        "\n",
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "import functools\n",
        "\n",
        "class ResearchTeamState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    team_members: List[str]\n",
        "    next: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvPM5msq_18C"
      },
      "source": [
        "Notice how we've used `messages`, `team_members`, and `next`.\n",
        "\n",
        "These states will help us understand:\n",
        "\n",
        "1. What we've done so far (`messages`)\n",
        "2. Which team members we have access to (`team_members`)\n",
        "3. Which team member is up next! (`next`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu7B_6qHAFjK"
      },
      "source": [
        "### Research Team LLM\n",
        "\n",
        "We'll be using `gpt-4o-mini` today. This LLM is going to be doing a lot of reasoning - but we also want to keep our costs down, so we'll use a lightweight; but powerful, model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dTNqrip8AcKR"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfb_VCNKIy9w"
      },
      "source": [
        "##### ❓ Question #1:\n",
        "\n",
        "Why is a \"powerful\" LLM important for this use-case?\n",
        "\n",
        "What tasks must our Agent perform that make it such that the LLM's reasoning capability is a potential limiter?\n",
        "\n",
        "#### Answer\n",
        "The agents (especially the supervisor) need enough reasoning ability, to perform functions such as:\n",
        "reason about multiple steps\n",
        "coordinate between roles (supervsior)\n",
        "maintain a shared message history\n",
        "track intermediate steps (via scratchpad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_1LuMKAekf"
      },
      "source": [
        "### Research Team Agents & Nodes\n",
        "\n",
        "Now we can use our helper functions to create our agent nodes, with their related tools.\n",
        "\n",
        "Let's start with our search agent node."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzx6wuPoAlPq"
      },
      "source": [
        "#### Research Team: Search Agent\n",
        "\n",
        "We're going to give our agent access to the Tavily tool, power it with our GPT-4o Mini model, and then create its node - and name it `Search`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loom note\n",
        "I find it interesting that the differentiation between agent types comes down to a very brief system prompt!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "FIlLPxj7Atpj"
      },
      "outputs": [],
      "source": [
        "search_agent = create_agent(\n",
        "    llm,\n",
        "    [tavily_tool],\n",
        "    \"You are a research assistant who can search for up-to-date info using the tavily search engine.\",\n",
        ")\n",
        "search_node = functools.partial(agent_node, agent=search_agent, name=\"Search\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emLtesudA9Dd"
      },
      "source": [
        "#### Research Team: RAG Agent Node\n",
        "\n",
        "Now we can wrap our LCEL RAG pipeline in an agent node as well, using the LCEL RAG pipeline as the tool, as created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z-nnAG9XA_p7"
      },
      "outputs": [],
      "source": [
        "research_agent = create_agent(\n",
        "    llm,\n",
        "    [retrieve_information],\n",
        "    \"You are a research assistant who can provide specific information on the student loan policies\",\n",
        ")\n",
        "research_node = functools.partial(agent_node, agent=research_agent, name=\"LoanRetriever\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA5z6T1CBeSc"
      },
      "source": [
        "### Research Team Supervisor Agent\n",
        "\n",
        "Notice that we're not yet creating our supervisor *node*, simply the agent here.\n",
        "\n",
        "Also notice how we need to provide a few extra pieces of information - including which tools we're using.\n",
        "\n",
        "> NOTE: It's important to use the *exact* tool name, as that is how the LLM will reference the tool. Also, it's important that your tool name is all a single alphanumeric string!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loom Note\n",
        "The supervisor gets a slightly more elaborate \"job description\" (system prompt) 😀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "J0g8CQMBrtFs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/xc/ddmjsd0x4sl7n58bhfwn6dv00000gn/T/ipykernel_73358/488856706.py:34: LangChainDeprecationWarning: The method `BaseChatOpenAI.bind_functions` was deprecated in langchain-openai 0.2.1 and will be removed in 1.0.0. Use :meth:`~langchain_openai.chat_models.base.ChatOpenAI.bind_tools` instead.\n",
            "  | llm.bind_functions(functions=[function_def], function_call=\"route\")\n"
          ]
        }
      ],
      "source": [
        "supervisor_agent = create_team_supervisor(\n",
        "    llm,\n",
        "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following workers:  Search, LoanRetriever. Given the following user request,\"\n",
        "    \" determine the subject to be researched and respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. \"\n",
        "    \" You should never ask your team to do anything beyond research. They are not required to write content or posts.\"\n",
        "    \" You should only pass tasks to workers that are specifically research focused.\"\n",
        "    \" When finished, respond with FINISH.\"),\n",
        "    [\"Search\", \"LoanRetriever\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qohn0DcgB_U1"
      },
      "source": [
        "### Research Team Graph Creation\n",
        "\n",
        "Now that we have our research team agent nodes created, and our supervisor agent - let's finally construct our graph!\n",
        "\n",
        "We'll start by creating our base graph from our state, and then adding the nodes/agent we've created as nodes on our LangGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "p0s2GAgJCN8G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x1244f0350>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "research_graph = StateGraph(ResearchTeamState)\n",
        "\n",
        "research_graph.add_node(\"Search\", search_node)\n",
        "research_graph.add_node(\"LoanRetriever\", research_node)\n",
        "research_graph.add_node(\"supervisor\", supervisor_agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33qixRGNCaAX"
      },
      "source": [
        "Now we can define our edges - include our conditional edge from our supervisor to our agent nodes.\n",
        "\n",
        "Notice how we're always routing our agent nodes back to our supervisor!\n",
        "\n",
        "#### Study notes: Noted!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yYSJIhijsGyg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x1244f0350>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "research_graph.add_edge(\"Search\", \"supervisor\")\n",
        "research_graph.add_edge(\"LoanRetriever\", \"supervisor\")\n",
        "research_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\"Search\": \"Search\", \"LoanRetriever\": \"LoanRetriever\", \"FINISH\": END},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgGcuZzkCj1-"
      },
      "source": [
        "Now we can set our supervisor node as the entry point, and compile our graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1l-1I2Z3CnPX"
      },
      "outputs": [],
      "source": [
        "research_graph.set_entry_point(\"supervisor\")\n",
        "compiled_research_graph = research_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDwQpYTSEY13"
      },
      "source": [
        "#### Display Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ⚠️ Fix for Graph Visualization Error\n",
        "\n",
        "The cell below causes an error on Apple Silicon Macs due to Chromium compatibility issues with pyppeteer. \n",
        "\n",
        "**Error:** `OSError: [Errno 86] Bad CPU type in executable`\n",
        "\n",
        "**Solution:** Use `MermaidDrawMethod.API` instead of `MermaidDrawMethod.PYPPETEER`\n",
        "\n",
        "Run the fixed cell below instead of the original cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Fixed version of the graph visualization - use API instead of PYPPETEER\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        compiled_research_graph.get_graph().draw_mermaid_png(\n",
        "            curve_style=CurveStyle.LINEAR,\n",
        "            node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"),\n",
        "            wrap_label_n_words=9,\n",
        "            output_file_path=None,\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "            background_color=\"white\",\n",
        "            padding=10,\n",
        "        )\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"research_graph.png\", \"wb\") as f:\n",
        "    f.write(\n",
        "        compiled_research_graph.get_graph().draw_mermaid_png(\n",
        "            curve_style=CurveStyle.LINEAR,\n",
        "            node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"),\n",
        "            wrap_label_n_words=9,\n",
        "            output_file_path=None,\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "            background_color=\"white\",\n",
        "            padding=10,\n",
        "        )\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loom Note\n",
        "Graphing error fixed by Cursor (Claude)\n",
        "### Root Cause\n",
        "- **pyppeteer** downloads a Chromium binary that may not be compatible with Apple Silicon (ARM64) architecture\n",
        "- The downloaded Chromium was built for x86-64 and cannot run on ARM64 processors\n",
        "- This affects the `MermaidDrawMethod.PYPPETEER` rendering method\n",
        "\n",
        "### Solution\n",
        "Changed the `draw_method` parameter from:\n",
        "```python\n",
        "draw_method=MermaidDrawMethod.PYPPETEER  # ❌ Uses local Chromium\n",
        "```\n",
        "\n",
        "To:\n",
        "```python\n",
        "draw_method=MermaidDrawMethod.API  # ✅ Uses online Mermaid service\n",
        "```\n",
        "\n",
        "### How It Works\n",
        "- **PYPPETEER method**: Downloads and runs local Chromium browser to render diagrams\n",
        "- **API method**: Sends diagram code to Mermaid's online service and receives back a PNG image\n",
        "- **Result**: Same visual output, no local browser dependency\n",
        "\n",
        "### Benefits\n",
        "- ✅ Works on all architectures (Intel x86-64, Apple Silicon ARM64)\n",
        "- ✅ No local browser installation issues\n",
        "- ✅ No pyppeteer dependency problems\n",
        "- ✅ Faster rendering (no browser startup time)\n",
        "\n",
        "This fix ensures the LangGraph visualizations work reliably across different system architectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "l8n6SXhpEa2b",
        "outputId": "6dac5e4e-daed-4d7a-d629-cd83119e7e2c"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[Errno 86] Bad CPU type in executable: '/Users/family/Library/Application Support/pyppeteer/local-chromium/1181205/chrome-mac/Chromium.app/Contents/MacOS/Chromium'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CurveStyle, MermaidDrawMethod, NodeStyles\n\u001b[32m      4\u001b[39m display(\n\u001b[32m      5\u001b[39m     Image(\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         \u001b[43mcompiled_research_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcurve_style\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCurveStyle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLINEAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnode_colors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNodeStyles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m#ffdfba\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m#baffc9\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m#fad7de\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwrap_label_n_words\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMermaidDrawMethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPYPPETEER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     )\n\u001b[32m     16\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph.py:693\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[39m\n\u001b[32m    685\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    687\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    688\u001b[39m     curve_style=curve_style,\n\u001b[32m    689\u001b[39m     node_colors=node_colors,\n\u001b[32m    690\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    691\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    692\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:287\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m draw_method == MermaidDrawMethod.PYPPETEER:\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     img_bytes = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_render_mermaid_using_pyppeteer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m    293\u001b[39m     img_bytes = _render_mermaid_using_api(\n\u001b[32m    294\u001b[39m         mermaid_syntax,\n\u001b[32m    295\u001b[39m         output_file_path=output_file_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m         retry_delay=retry_delay,\n\u001b[32m    299\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:325\u001b[39m, in \u001b[36m_render_mermaid_using_pyppeteer\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, padding, device_scale_factor)\u001b[39m\n\u001b[32m    322\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInstall Pyppeteer to use the Pyppeteer method: `pip install pyppeteer`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m browser = \u001b[38;5;28;01mawait\u001b[39;00m launch()\n\u001b[32m    326\u001b[39m page = \u001b[38;5;28;01mawait\u001b[39;00m browser.newPage()\n\u001b[32m    328\u001b[39m \u001b[38;5;66;03m# Setup Mermaid JS\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/pyppeteer/launcher.py:307\u001b[39m, in \u001b[36mlaunch\u001b[39m\u001b[34m(options, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlaunch\u001b[39m(options: \u001b[38;5;28mdict\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any) -> Browser:\n\u001b[32m    240\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Start chrome process and return :class:`~pyppeteer.browser.Browser`.\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[33;03m    This function is a shortcut to :meth:`Launcher(options, **kwargs).launch`.\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[33;03m    Available options are:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    305\u001b[39m \u001b[33;03m        option with extreme caution.\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m Launcher(options, **kwargs).launch()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/pyppeteer/launcher.py:148\u001b[39m, in \u001b[36mLauncher.launch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    145\u001b[39m     options[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = subprocess.DEVNULL\n\u001b[32m    146\u001b[39m     options[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = subprocess.STDOUT\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m \u001b[38;5;28mself\u001b[39m.proc = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_close_process\u001b[39m(*args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chromeClosed:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1022\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/subprocess.py:1955\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1953\u001b[39m     err_msg = os.strerror(errno_num)\n\u001b[32m   1954\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1955\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[32m   1956\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1957\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
            "\u001b[31mOSError\u001b[39m: [Errno 86] Bad CPU type in executable: '/Users/family/Library/Application Support/pyppeteer/local-chromium/1181205/chrome-mac/Chromium.app/Contents/MacOS/Chromium'"
          ]
        }
      ],
      "source": [
        "# This cell failed. Cursor fixed it.\n",
        "# from IPython.display import Image, display\n",
        "# from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "# display(\n",
        "#     Image(\n",
        "#         compiled_research_graph.get_graph().draw_mermaid_png(\n",
        "#             curve_style=CurveStyle.LINEAR,\n",
        "#             node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"),\n",
        "#             wrap_label_n_words=9,\n",
        "#             output_file_path=None,\n",
        "#             draw_method=MermaidDrawMethod.PYPPETEER,\n",
        "#             background_color=\"white\",\n",
        "#             padding=10,\n",
        "#         )\n",
        "#     )\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfRvA2QfCqFL"
      },
      "source": [
        "The next part is key - since we need to \"wrap\" our LangGraph in order for it to be compatible in the following steps - let's create an LCEL chain out of it!\n",
        "\n",
        "This allows us to \"broadcast\" messages down to our Research Team LangGraph!\n",
        "\n",
        "#### Study note\n",
        "Explanation from ChatGPT\n",
        "You can’t just plug a LangGraph directly into another chain or agent — you need to wrap it so it behaves like a runnable object (something you can call with .invoke()).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1G7hmEINCx3i"
      },
      "outputs": [],
      "source": [
        "def enter_chain(message: str):\n",
        "    results = {\n",
        "        \"messages\": [HumanMessage(content=message)],\n",
        "    }\n",
        "    return results\n",
        "\n",
        "research_chain = enter_chain | compiled_research_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGdoCdXWC7Pi"
      },
      "source": [
        "Now, finally, we can take it for a spin!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIDpFIg2sRUl",
        "outputId": "bb3803d4-5b32-4b0a-c8a1-1a1917425812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'LoanRetriever'}}\n",
            "---\n",
            "{'LoanRetriever': {'messages': [HumanMessage(content=\"The provided information does not specify a single maximum student loan amount for the year 2025. However, it outlines the annual loan limits for different categories:\\n\\n- For **dependent undergraduate students**, the maximum annual loan limit is **$7,500** for the fourth year of study.\\n- For **independent undergraduates**, the maximum annual loan limit is **$12,500**.\\n- For **graduate and professional students**, the total aggregate limit is **$138,500**, which includes loans taken for undergraduate study.\\n\\nThe context also mentions that loan limits can be prorated based on enrollment hours and the student's progression through grade levels. However, it does not provide a singular maximum amount applicable to all students in 2025.\", additional_kwargs={}, response_metadata={}, name='LoanRetriever')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for s in research_chain.stream(\n",
        "    \"What is the maximum student loan in 2025?\", {\"recursion_limit\": 100}\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHAgsbwIIhwj"
      },
      "source": [
        "##### 🏗️ Activity #2:\n",
        "\n",
        "Using whatever drawing application you wish - please label the flow above on a diagram of your graph.\n",
        "\n",
        "#### Answer for Activity #2\n",
        "\n",
        "This diagram illustrates a sample execution trace through the graph, based on above output:\n",
        "\n",
        "\n",
        "![HW6 Activity 2 – Annotated Graph](./HW6_Activity2_annotated_graph.png)\n",
        "\n",
        "#### Activity 2 note:\n",
        "Here is the output from the above code cell, that the annotation is based on\n",
        "Saving it here, to show that it matches the annotation\n",
        "\n",
        "{'supervisor': {'next': 'LoanRetriever'}}\n",
        "---\n",
        "{'LoanRetriever': {'messages': [HumanMessage(content=\"The provided information does not specify a single maximum student loan amount for the year 2025. However, it outlines the annual loan limits for different categories:\\n\\n- For **dependent undergraduate students**, the maximum annual loan limit is **$7,500** for the fourth year of study.\\n- For **independent undergraduates**, the maximum annual loan limit is **$12,500**.\\n- For **graduate and professional students**, the total aggregate limit is **$138,500**, which includes loans taken for undergraduate study.\\n\\nThe context also mentions that loan limits can be prorated based on enrollment hours and the student's progression through grade levels. However, it does not provide a singular maximum amount applicable to all students in 2025.\", additional_kwargs={}, response_metadata={}, name='LoanRetriever')]}}\n",
        "---\n",
        "{'supervisor': {'next': 'FINISH'}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH70eHGlJbq4"
      },
      "source": [
        "##### ❓ Question #2:\n",
        "\n",
        "How could you make sure your Agent uses specific tools that you wish it to use? Are there any ways to concretely set a flow through tools?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iktcBorGXmAW"
      },
      "source": [
        "# 🤝 BREAKOUT ROOM #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejsHCZZ2EmwM"
      },
      "source": [
        "## Task 4: Document Writing Team - A LangGraph for Planning, Writing, and Editing a Formal Complaint Response.\n",
        "\n",
        "Let's run it all back, this time specifically creating tools, agent nodes, and a graph for Planning, Writing, and Editing a Formal Complaint Response!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Previous Complaint Data\n",
        "\n",
        "Let's add a retriever for [previous complaint data](./data/complaints.csv) here!\n",
        "\n",
        "This will allow our response writing team reference previous responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'data/complaints.csv', 'row': 0}, page_content=\"Consumer complaint narrative: The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\\nCompany public response: None\\nCompany response to consumer: Closed with explanation\")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.document_loaders import CSVLoader\n",
        "\n",
        "complaint_loader = CSVLoader(\"data/complaints.csv\", content_columns=[\"Consumer complaint narrative\", \"Company public response\", \"Company response to consumer\"])\n",
        "complaints = complaint_loader.load()\n",
        "complaints[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "qdrant_complaint_vectorstore = Qdrant.from_documents(\n",
        "    documents=complaints,\n",
        "    embedding=embedding_model,\n",
        "    location=\":memory:\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "qdrant_complaint_retriever = qdrant_complaint_vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4awQtZ-oFUN-"
      },
      "source": [
        "### Tool Creation\n",
        "\n",
        "Let's create some tools that will help us understand, open, work with, and edit documents to our liking!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Study notes\n",
        "This is my first experience with Python \"decorators\".\n",
        "ChatGPT says:\n",
        "> A decorator is a special function that wraps another function to add extra behavior without changing its core logic.\n",
        "\n",
        "Which apparently means if you call it a tool, it becomes a tool. Wow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ptXilgparOkq"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Dict, Optional\n",
        "from typing_extensions import TypedDict\n",
        "import uuid\n",
        "import os\n",
        "\n",
        "os.makedirs('./content/data', exist_ok=True)\n",
        "\n",
        "def create_random_subdirectory():\n",
        "    random_id = str(uuid.uuid4())[:8]  # Use first 8 characters of a UUID\n",
        "    subdirectory_path = os.path.join('./content/data', random_id)\n",
        "    os.makedirs(subdirectory_path, exist_ok=True)\n",
        "    return subdirectory_path\n",
        "\n",
        "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
        "\n",
        "@tool\n",
        "def create_outline(\n",
        "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
        "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
        ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
        "    \"\"\"Create and save an outline.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        for i, point in enumerate(points):\n",
        "            file.write(f\"{i + 1}. {point}\\n\")\n",
        "    return f\"Outline saved to {file_name}\"\n",
        "\n",
        "\n",
        "@tool\n",
        "def read_document(\n",
        "    file_name: Annotated[str, \"File path to save the document.\"],\n",
        "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
        "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
        ") -> str:\n",
        "    \"\"\"Read the specified document.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "    if start is not None:\n",
        "        start = 0\n",
        "    return \"\\n\".join(lines[start:end])\n",
        "\n",
        "@tool\n",
        "def write_document(\n",
        "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
        "    file_name: Annotated[str, \"File path to save the document.\"],\n",
        ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
        "    \"\"\"Create and save a text document.\"\"\"\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.write(content)\n",
        "    return f\"Document saved to {file_name}\"\n",
        "\n",
        "### Previous Complaint Data\n",
        "@tool \n",
        "def reference_previous_responses(\n",
        "    query: Annotated[str, \"The query to search for in the previous responses.\"],\n",
        ") -> Annotated[str, \"The previous responses that match the query.\"]:\n",
        "    \"\"\"Search for previous responses that match the query.\"\"\"\n",
        "    return qdrant_complaint_retriever.invoke(query)\n",
        "\n",
        "\n",
        "@tool\n",
        "def edit_document(\n",
        "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
        "    inserts: Annotated[\n",
        "        Dict[int, str],\n",
        "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
        "    ] = {},\n",
        ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
        "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    sorted_inserts = sorted(inserts.items())\n",
        "\n",
        "    for line_number, text in sorted_inserts:\n",
        "        if 1 <= line_number <= len(lines) + 1:\n",
        "            lines.insert(line_number - 1, text + \"\\n\")\n",
        "        else:\n",
        "            return f\"Error: Line number {line_number} is out of range.\"\n",
        "\n",
        "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "    return f\"Document edited and saved to {file_name}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 🏗️ Activity #3:\n",
        "\n",
        "Describe, briefly, what each of these tools is doing in your own words.\n",
        "\n",
        "#### Answer to Activity #3\n",
        "\n",
        "Fortunately, the tools are well named and descriptions are very English. Plus the triple-quoted comments pretty much say it all.  \n",
        "Here it is in my words:\n",
        "\n",
        "> **create_outline**: creates an outline (list of main points), and writes it to the given filename  \n",
        "> **read_document**: reads the document, at the specified directory / filename, from the given start to end line (defaulting to the whole file)  \n",
        "> **write_document**: writes the given text to the given filepath  \n",
        "> **reference_previous_response**: given a string to search for, it searches the Qdrant vector store for a match. (I'm assuming this is some sort of semantic match, rather than an exact match — but I would have to trace back through the code or ask ChatGPT to confirm.)  \n",
        "> **edit_document**: given a file path, and a location (line number) in the file, insert some text  \n",
        "\n",
        "---\n",
        "\n",
        "Let's see if I also understand the inputs/outputs of each (less certain about this):\n",
        "\n",
        "- **create_outline**  \n",
        "  - *Inputs*: file path, list of main points  \n",
        "  - *Action*: creates outline  \n",
        "  - *Outputs*: name of saved file\n",
        "\n",
        "- **read_document**  \n",
        "  - *Inputs*: filepath, and optionally range of lines  \n",
        "  - *Action*: \"read\" the text into a data object  \n",
        "  - *Output*: ~~list~~ **string** containing the lines (`lines[start:end]`) *(corrected by ChatGPT)*\n",
        "\n",
        "- **write_document**  \n",
        "  - *Inputs*: text  \n",
        "  - *Action*: write text  \n",
        "  - *Outputs*: path to the filename that has the text\n",
        "\n",
        "- **reference_previous_response**  \n",
        "  - *Inputs*: a query  \n",
        "  - *Action*: finds the closest match (in the vector store)  \n",
        "  - *Outputs*: an annotated string\n",
        "\n",
        "- **edit_document**  \n",
        "  - *Inputs*: file path, text, and location (line number) in file to put the text  \n",
        "  - *Action*: writes text to specified location  \n",
        "  - *Outputs*: updated file\n",
        "\n",
        "---\n",
        "\n",
        "I wrote the text; ChatGPT said it was pretty good, and made one correction (noted above). Also used ChatGPT to re-format the Markdown.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__Jw_XBIFwwa"
      },
      "source": [
        "### Document Writing State\n",
        "\n",
        "Just like with our Research Team state - we want to keep track of a few things, however this time - we also want to keep track of which files we've created - so let's add that here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DoU2YwJRu7wD"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from pathlib import Path\n",
        "\n",
        "class DocWritingState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    team_members: str\n",
        "    next: str\n",
        "    current_files: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p1kQShmGHCh"
      },
      "source": [
        "### Document Writing Prelude Function\n",
        "\n",
        "Since we have a working directory - we want to be clear about what our current working directory looks like - this helper function will allow us to do that cleanly!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "G79mUggQGLVq"
      },
      "outputs": [],
      "source": [
        "def prelude(state):\n",
        "    written_files = []\n",
        "    if not WORKING_DIRECTORY.exists():\n",
        "        WORKING_DIRECTORY.mkdir()\n",
        "    try:\n",
        "        written_files = [\n",
        "            f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\")\n",
        "        ]\n",
        "    except:\n",
        "        pass\n",
        "    if not written_files:\n",
        "        return {**state, \"current_files\": \"No files written.\"}\n",
        "    return {\n",
        "        **state,\n",
        "        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n",
        "        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbSre9agT9Gb"
      },
      "source": [
        "### Document Writing Node Creation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "v7oso327T_wa"
      },
      "outputs": [],
      "source": [
        "doc_writer_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert writing customer assistance responses.\\n\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "context_aware_doc_writer_agent = prelude | doc_writer_agent\n",
        "doc_writing_node = functools.partial(\n",
        "    agent_node, agent=context_aware_doc_writer_agent, name=\"DocWriter\"\n",
        ")\n",
        "\n",
        "note_taking_agent = create_agent(\n",
        "    llm,\n",
        "    [create_outline, read_document, reference_previous_responses],\n",
        "    (\"You are an expert senior researcher tasked with writing a customer assistance outline and\"\n",
        "    \" taking notes to craft a customer assistance response.\\n{current_files}\"),\n",
        ")\n",
        "context_aware_note_taking_agent = prelude | note_taking_agent\n",
        "note_taking_node = functools.partial(\n",
        "    agent_node, agent=context_aware_note_taking_agent, name=\"NoteTaker\"\n",
        ")\n",
        "\n",
        "copy_editor_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert copy editor who focuses on fixing grammar, spelling, and tone issues\\n\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "context_aware_copy_editor_agent = prelude | copy_editor_agent\n",
        "copy_editing_node = functools.partial(\n",
        "    agent_node, agent=context_aware_copy_editor_agent, name=\"CopyEditor\"\n",
        ")\n",
        "\n",
        "empathy_editor_agent = create_agent(\n",
        "    llm,\n",
        "    [write_document, edit_document, read_document],\n",
        "    (\"You are an expert in empathy, compassion, and understanding - you edit the document to make sure it's empathetic and compassionate.\"\n",
        "    \"Below are files currently in your directory:\\n{current_files}\"),\n",
        ")\n",
        "empathy_editor_agent = prelude | empathy_editor_agent\n",
        "empathy_node = functools.partial(\n",
        "    agent_node, agent=empathy_editor_agent, name=\"EmpathyEditor\"\n",
        ")\n",
        "\n",
        "doc_writing_supervisor = create_team_supervisor(\n",
        "    llm,\n",
        "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following workers: {team_members}. You should always verify the technical\"\n",
        "    \" contents after any edits are made. \"\n",
        "    \"Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When each team is finished,\"\n",
        "    \" you must respond with FINISH.\"),\n",
        "    [\"DocWriter\", \"NoteTaker\", \"EmpathyEditor\", \"CopyEditor\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUiNMpJBGXN0"
      },
      "source": [
        "### Document Writing Team LangGraph Construction\n",
        "\n",
        "This part is almost exactly the same (with a few extra nodes) as our Research Team LangGraph construction - so we'll leave it as one block!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Q6n8A1ytxVTv"
      },
      "outputs": [],
      "source": [
        "authoring_graph = StateGraph(DocWritingState)\n",
        "authoring_graph.add_node(\"DocWriter\", doc_writing_node)\n",
        "authoring_graph.add_node(\"NoteTaker\", note_taking_node)\n",
        "authoring_graph.add_node(\"CopyEditor\", copy_editing_node)\n",
        "authoring_graph.add_node(\"EmpathyEditor\", empathy_node)\n",
        "authoring_graph.add_node(\"supervisor\", doc_writing_supervisor)\n",
        "\n",
        "authoring_graph.add_edge(\"DocWriter\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"NoteTaker\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"CopyEditor\", \"supervisor\")\n",
        "authoring_graph.add_edge(\"EmpathyEditor\", \"supervisor\")\n",
        "\n",
        "authoring_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\n",
        "        \"DocWriter\": \"DocWriter\",\n",
        "        \"NoteTaker\": \"NoteTaker\",\n",
        "        \"CopyEditor\" : \"CopyEditor\",\n",
        "        \"EmpathyEditor\" : \"EmpathyEditor\",\n",
        "        \"FINISH\": END,\n",
        "    },\n",
        ")\n",
        "\n",
        "authoring_graph.set_entry_point(\"supervisor\")\n",
        "compiled_authoring_graph = authoring_graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fixed version of the authoring graph visualization - use API instead of PYPPETEER\n",
        "from IPython.display import Image, display\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        compiled_authoring_graph.get_graph().draw_mermaid_png(\n",
        "            curve_style=CurveStyle.LINEAR,\n",
        "            node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"),\n",
        "            wrap_label_n_words=9,\n",
        "            output_file_path=None,\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "            background_color=\"white\",\n",
        "            padding=10,\n",
        "        )\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx-EKGkHKUBO"
      },
      "source": [
        "#### Display Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "AZdOb3GZKSM7",
        "outputId": "6b64588d-5568-4234-d062-4dc83ea9abec"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[Errno 86] Bad CPU type in executable: '/Users/family/Library/Application Support/pyppeteer/local-chromium/1181205/chrome-mac/Chromium.app/Contents/MacOS/Chromium'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[32m      3\u001b[39m display(\n\u001b[32m      4\u001b[39m     Image(\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m         \u001b[43mcompiled_authoring_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcurve_style\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCurveStyle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLINEAR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnode_colors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNodeStyles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m#ffdfba\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m#baffc9\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m#fad7de\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwrap_label_n_words\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMermaidDrawMethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPYPPETEER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     )\n\u001b[32m     15\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph.py:693\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[39m\n\u001b[32m    685\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    687\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    688\u001b[39m     curve_style=curve_style,\n\u001b[32m    689\u001b[39m     node_colors=node_colors,\n\u001b[32m    690\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    691\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    692\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:287\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m draw_method == MermaidDrawMethod.PYPPETEER:\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     img_bytes = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_render_mermaid_using_pyppeteer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m    293\u001b[39m     img_bytes = _render_mermaid_using_api(\n\u001b[32m    294\u001b[39m         mermaid_syntax,\n\u001b[32m    295\u001b[39m         output_file_path=output_file_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m         retry_delay=retry_delay,\n\u001b[32m    299\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/asyncio/tasks.py:277\u001b[39m, in \u001b[36mTask.__step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    275\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    276\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         result = coro.throw(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/langchain_core/runnables/graph_mermaid.py:325\u001b[39m, in \u001b[36m_render_mermaid_using_pyppeteer\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, padding, device_scale_factor)\u001b[39m\n\u001b[32m    322\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInstall Pyppeteer to use the Pyppeteer method: `pip install pyppeteer`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m browser = \u001b[38;5;28;01mawait\u001b[39;00m launch()\n\u001b[32m    326\u001b[39m page = \u001b[38;5;28;01mawait\u001b[39;00m browser.newPage()\n\u001b[32m    328\u001b[39m \u001b[38;5;66;03m# Setup Mermaid JS\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/pyppeteer/launcher.py:307\u001b[39m, in \u001b[36mlaunch\u001b[39m\u001b[34m(options, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlaunch\u001b[39m(options: \u001b[38;5;28mdict\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs: Any) -> Browser:\n\u001b[32m    240\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Start chrome process and return :class:`~pyppeteer.browser.Browser`.\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[33;03m    This function is a shortcut to :meth:`Launcher(options, **kwargs).launch`.\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[33;03m    Available options are:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    305\u001b[39m \u001b[33;03m        option with extreme caution.\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m Launcher(options, **kwargs).launch()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Mobile Documents/com~apple~CloudDocs/AppDev/AIMakerspaceCode/AIE7homework/06_Multi_Agent_with_LangGraph/.venv/lib/python3.11/site-packages/pyppeteer/launcher.py:148\u001b[39m, in \u001b[36mLauncher.launch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    145\u001b[39m     options[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = subprocess.DEVNULL\n\u001b[32m    146\u001b[39m     options[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = subprocess.STDOUT\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m \u001b[38;5;28mself\u001b[39m.proc = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_close_process\u001b[39m(*args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chromeClosed:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1022\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/subprocess.py:1955\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1953\u001b[39m     err_msg = os.strerror(errno_num)\n\u001b[32m   1954\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1955\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[32m   1956\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1957\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
            "\u001b[31mOSError\u001b[39m: [Errno 86] Bad CPU type in executable: '/Users/family/Library/Application Support/pyppeteer/local-chromium/1181205/chrome-mac/Chromium.app/Contents/MacOS/Chromium'"
          ]
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(\n",
        "    Image(\n",
        "        compiled_authoring_graph.get_graph().draw_mermaid_png(\n",
        "            curve_style=CurveStyle.LINEAR,\n",
        "            node_colors=NodeStyles(first=\"#ffdfba\", last=\"#baffc9\", default=\"#fad7de\"),\n",
        "            wrap_label_n_words=9,\n",
        "            output_file_path=None,\n",
        "            draw_method=MermaidDrawMethod.PYPPETEER,\n",
        "            background_color=\"white\",\n",
        "            padding=10,\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB_rOw1hGpwd"
      },
      "source": [
        "Just as before - we'll need to create an \"interface\" between the level above, and our graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "G-RbbCKoG_nt"
      },
      "outputs": [],
      "source": [
        "def enter_chain(message: str, members: List[str]):\n",
        "    results = {\n",
        "        \"messages\": [HumanMessage(content=message)],\n",
        "        \"team_members\": \", \".join(members),\n",
        "    }\n",
        "    return results\n",
        "\n",
        "authoring_chain = (\n",
        "    functools.partial(enter_chain, members=authoring_graph.nodes)\n",
        "    | authoring_graph.compile()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgyhpTrRNgQd"
      },
      "source": [
        "Now we can test this out!\n",
        "\n",
        "> NOTE: It is possible you may see an error here - rerun the cell to clear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWUxv4XDx3kg",
        "outputId": "62ee7d3d-31ba-4348-b852-7fd96f6875ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'DocWriter'}}\n",
            "---\n",
            "{'DocWriter': {'messages': [HumanMessage(content='I have created a customer assistance response regarding the positioning of Student Loans as it relates to low-income students. If you need any further assistance or adjustments, just let me know!', additional_kwargs={}, response_metadata={}, name='DocWriter')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'NoteTaker'}}\n",
            "---\n",
            "{'NoteTaker': {'messages': [HumanMessage(content=\"Here is a customer assistance response regarding the positioning of Student Loans as it relates to low-income students:\\n\\n---\\n\\nSubject: Understanding Student Loans for Low-Income Students\\n\\nDear [Customer's Name],\\n\\nThank you for reaching out to us with your questions regarding Student Loans and their impact on low-income students.\\n\\nStudent loans can serve as a crucial financial resource that helps low-income students access higher education. However, it's important to recognize the complexities involved in borrowing and repayment. Here’s a brief overview of how student loans relate to low-income students:\\n\\n1. **Accessibility:** Student loans can bridge the gap between the costs of college education and the financial resources available. For many low-income students, federal student loans provide an opportunity to afford tuition and other expenses, allowing them to pursue their academic and career goals.\\n\\n2. **Federal Aid Programs:** The federal government offers various loan options tailored for low-income students, such as Direct Subsidized Loans, which do not accrue interest while the student is enrolled at least half-time. Additionally, low-income students may be eligible for federal grants, which do not require repayment.\\n\\n3. **Affordability Concerns:** While student loans provide accessibility, the repayment burden can be significant. It’s essential for low-income students to carefully consider how much they are borrowing and understand the financial implications after graduation. Financial literacy resources are available to help navigate these decisions.\\n\\n4. **Loan Forgiveness Programs:** There are also programs aimed at assisting graduates with student loan forgiveness based on specific criteria, such as income-driven repayment plans or public service jobs. Low-income students should explore these options as they consider their career paths.\\n\\nIn conclusion, while student loans can provide necessary financial support for low-income students, it is essential to approach borrowing with an informed perspective. We encourage students to research all available financial aid options, including scholarships and grants, to minimize their reliance on loans.\\n\\nPlease feel free to reach out if you have any further questions or need assistance with specific loan programs. We are here to support you in your educational journey.\\n\\nBest regards,\\n\\n[Your Name]  \\n[Your Position]  \\n[Your Contact Information]  \\n[Company Name]  \\n[Company Contact Information]  \\n\\n--- \\n\\nIf you need any modifications or additional information, let me know!\", additional_kwargs={}, response_metadata={}, name='NoteTaker')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'EmpathyEditor'}}\n",
            "---\n",
            "{'EmpathyEditor': {'messages': [HumanMessage(content='I have written and saved the customer assistance response regarding student loans and their relation to low-income students. If you need any further modifications or additional content, feel free to let me know!', additional_kwargs={}, response_metadata={}, name='EmpathyEditor')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'CopyEditor'}}\n",
            "---\n",
            "{'CopyEditor': {'messages': [HumanMessage(content='The customer assistance response regarding student loans and their relation to low-income students has been successfully saved. If you need any further modifications or additional content, feel free to let me know!', additional_kwargs={}, response_metadata={}, name='CopyEditor')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for s in authoring_chain.stream(\n",
        "    \"Write a customer assistance response on the positioning of Student Loans as it relates to low income students.\",\n",
        "    {\"recursion_limit\": 100},\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpW2R9SUHGUq"
      },
      "source": [
        "## Task 5: Meta-Supervisor and Full Graph\n",
        "\n",
        "Finally, now that we have our two LangGraph agents (some of which are already multi-agent), we can build a supervisor that sits above all of them!\n",
        "\n",
        "The final process, surprisingly, is quite straight forward!\n",
        "\n",
        "Let's jump in!\n",
        "\n",
        "First off - we'll need to create our supervisor agent node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "wkpxeUf9ygKp"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "supervisor_node = create_team_supervisor(\n",
        "    llm,\n",
        "    \"You are a supervisor tasked with managing a conversation between the\"\n",
        "    \" following teams: {team_members}. Given the following user request,\"\n",
        "    \" respond with the worker to act next. Each worker will perform a\"\n",
        "    \" task and respond with their results and status. When all workers are finished,\"\n",
        "    \" you must respond with FINISH.\",\n",
        "    [\"Research team\", \"Response team\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUvOh_xWIKig"
      },
      "source": [
        "We'll also create our new state - as well as some methods to help us navigate the new state and the subgraphs.\n",
        "\n",
        "> NOTE: We only pass the most recent message from the parent graph to the subgraph, and we only extract the most recent message from the subgraph to include in the state of the parent graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "O7HJ8MF0yh_i"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    next: str\n",
        "\n",
        "def get_last_message(state: State) -> str:\n",
        "    return state[\"messages\"][-1].content\n",
        "\n",
        "def join_graph(response: dict):\n",
        "    return {\"messages\": [response[\"messages\"][-1]]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5RHao1sIanG"
      },
      "source": [
        "Next, we'll create our base graph.\n",
        "\n",
        "Notice how each node we're adding is *AN ENTIRE LANGGRAPH AGENT* (wrapped into an LCEL chain with our helper functions above)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "PfCWABCMIaFy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x14efcbdd0>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "super_graph = StateGraph(State)\n",
        "\n",
        "super_graph.add_node(\"Research team\", get_last_message | research_chain | join_graph)\n",
        "super_graph.add_node(\"Response team\", get_last_message | authoring_chain | join_graph)\n",
        "super_graph.add_node(\"supervisor\", supervisor_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpwpUXMtI62E"
      },
      "source": [
        "Next, we'll create our edges!\n",
        "\n",
        "This process is completely idenctical to what we've seen before - just addressing the LangGraph subgraph nodes instead of individual nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "tLtjRuUYI-fx"
      },
      "outputs": [],
      "source": [
        "super_graph.add_edge(\"Research team\", \"supervisor\")\n",
        "super_graph.add_edge(\"Response team\", \"supervisor\")\n",
        "super_graph.add_conditional_edges(\n",
        "    \"supervisor\",\n",
        "    lambda x: x[\"next\"],\n",
        "    {\n",
        "        \"Response team\": \"Response team\",\n",
        "        \"Research team\": \"Research team\",\n",
        "        \"FINISH\": END,\n",
        "    },\n",
        ")\n",
        "super_graph.set_entry_point(\"supervisor\")\n",
        "compiled_super_graph = super_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1KMfFqgJKw8"
      },
      "source": [
        "That's it!\n",
        "\n",
        "Now we can finally use our full agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M6wUDR-yk8s",
        "outputId": "056fe89e-5a81-4852-f0cb-35367da8cef0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'supervisor': {'next': 'Research team'}}\n",
            "---\n",
            "{'Research team': {'messages': [HumanMessage(content='**Customer Assistance Response: Positioning of Student Loans for Low Income Students**\\n\\nDear Valued Student,\\n\\nWe understand that navigating the complexities of student loans can be particularly challenging for low-income students. It’s essential to recognize the available support systems specifically designed to assist you in achieving your educational goals without overwhelming financial stress.\\n\\n### 1. **Types of Loans Available**\\nAs a low-income student, you may qualify for **Direct Subsidized Loans**, which are designed for those with demonstrated financial need. The federal government pays the interest on these loans while you are in school and during certain deferment periods. Conversely, **Direct Unsubsidized Loans** are available to all students regardless of financial need, but interest accrues during all periods.\\n\\nFor more detailed information about these types of loans, please visit [Federal Student Aid](https://studentaid.gov/understand-aid/types/loans/subsidized-unsubsidized).\\n\\n### 2. **Income-Driven Repayment Plans**\\nOnce you graduate or leave school, managing student loan repayment can be daunting, especially for low-income borrowers. Here, **Income-Driven Repayment (IDR) Plans** come into play. These plans adjust your monthly payments based on your income and family size, ensuring that your payments remain manageable. You may even qualify for loan forgiveness after making regular payments for a specified number of years.\\n\\nFor more information on IDR Plans, visit [Income-Driven Repayment](https://studentaid.gov/idr).\\n\\n### 3. **Additional Financial Aid Resources**\\nIn addition to loans, numerous scholarships and financial aid programs are available for low-income students. We highly encourage you to explore local and federal financial assistance options to maximize your funding opportunities. For a comprehensive overview of related programs, please check out [State Financial Assistance Programs](https://mhec.maryland.gov/preparing/pages/financialaid/descriptions.aspx).\\n\\n### 4. **Conclusion**\\nIn summary, while the student loan landscape can be challenging, ample resources are available to help low-income students thrive academically without the constant burden of financial strain. Do not hesitate to reach out if you have further questions or need personalized assistance with your financial aid options.\\n\\nBest Regards,\\n\\n[Your Name]  \\n[Your Position]  \\n[Your Contact Information]\\n\\n---\\n\\n*Note: This information has been updated to reflect the latest data on student loans relevant to low-income students as of 2023, including types of loans and income-driven repayment plans.*\\n\\n*Please ensure that this information is reviewed and proofread by relevant teams before distribution, as updates and changes to student loan policies may occur regularly.*', additional_kwargs={}, response_metadata={}, name='LoanRetriever')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'Research team'}}\n",
            "---\n",
            "{'Research team': {'messages': [HumanMessage(content=\"### Updated Guidance on Student Loans for Low-Income Students\\n\\nDear Valued Student,\\n\\nAs you embark on your educational journey, we wish to provide you with important updates regarding student loans, particularly for those from low-income backgrounds. Understanding your options is critical, especially with recent changes in regulations and support systems.\\n\\n### 1. **Available Loan Types**\\nLow-income students can benefit significantly from **Direct Subsidized Loans**, wherein the federal government covers interest while you're in school. In contrast, **Direct Unsubsidized Loans** accrue interest during all periods and are available irrespective of financial need. For more in-depth information, please visit [Federal Student Aid](https://studentaid.gov/understand-aid/types/loans/subsidized-unsubsidized).\\n\\n### 2. **Changes in Income-Driven Repayment Plans**\\nWith the conclusion of the COVID-19 relief period as of September 1, 2023, student loan payments have resumed. Many students, especially those with lower incomes, may not be aware of alternative payment options. **Income-Driven Repayment (IDR) Plans** can help by adjusting monthly payments according to income and family size. Recent court rulings have paused certain changes to these plans, affecting aspects like payment formulas and forgiveness under various plans. For the latest information on these developments, you can visit [Income-Driven Repayment](https://studentaid.gov/announcements-events/idr-court-actions).\\n\\n### 3. **Exploring Financial Aid Options**\\nBeyond loans, numerous scholarships and additional federal aid programs are available specifically for low-income students. Utilizing tools like the Free Application for Federal Student Aid (FAFSA) can help uncover eligibility for various grants and scholarships. A comprehensive overview is available at [State Financial Assistance Programs](https://mhec.maryland.gov/preparing/pages/financialaid/descriptions.aspx).\\n\\n### 4. **Conclusion**\\nWhile the landscape of student loans is complex, especially for low-income students, a wealth of resources exists to support your educational aspirations without undue financial burden. We recommend reaching out for tailored assistance regarding your financial aid options.\\n\\nBest Regards,\\n\\n[Your Name]  \\n[Your Position]  \\n[Your Contact Information]\\n\\n---\\n\\n*This guidance reflects the latest updates on student loans relevant to low-income students as of 2023, including changes to repayment plans and available resources.*\", additional_kwargs={}, response_metadata={}, name='LoanRetriever')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'Response team'}}\n",
            "---\n",
            "{'Response team': {'messages': [HumanMessage(content='The document has been successfully edited to enhance empathy and compassion. If you need any further assistance or additional modifications, please feel free to ask!', additional_kwargs={}, response_metadata={}, name='CopyEditor')]}}\n",
            "---\n",
            "{'supervisor': {'next': 'FINISH'}}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "WORKING_DIRECTORY = Path(create_random_subdirectory())\n",
        "\n",
        "for s in compiled_super_graph.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(\n",
        "                content=\"Write a customer assistance response on the positioning of Student Loans as it relates to low income students. First consult the research team. Then make sure you consult the response team, and check for copy editing and dopeness, and write the file to disk.\"\n",
        "            )\n",
        "        ],\n",
        "    },\n",
        "    {\"recursion_limit\": 30},\n",
        "):\n",
        "    if \"__end__\" not in s:\n",
        "        print(s)\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuZAvSlJJpPP"
      },
      "source": [
        "## SAMPLE POST!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOEMCrXTJaxW"
      },
      "source": [
        "**Subject: Assistance Regarding Student Loans for Low-Income Students**\n",
        "\n",
        "Dear [Customer's Name],\n",
        "\n",
        "Thank you for reaching out regarding student loans and their implications for low-income students. We understand that navigating the financial aid landscape can be daunting, and we’re here to provide guidance and support.\n",
        "\n",
        "Student loans are instrumental in granting low-income students access to higher education, especially when scholarships and grants may fall short of covering the full cost of attendance. The federal student loan program presents various options designed to make borrowing more manageable for those in need.\n",
        "\n",
        "**1. Understanding Loan Types:**\n",
        "   - **Subsidized Loans**: These loans are available to undergraduate students who demonstrate financial need. The government covers the interest while the borrower is enrolled at least half-time, which can significantly alleviate the overall debt burden upon graduation.\n",
        "   - **Unsubsidized Loans**: Accessible to both undergraduate and graduate students, these loans do not require a demonstration of financial need. However, interest starts accruing from the moment the loan is disbursed.\n",
        "\n",
        "**2. Income-Based Repayment Options:**\n",
        "For low-income borrowers, Income-Based Repayment (IBR) plans can be especially advantageous. These plans ensure that monthly payments are based on income and family size, which helps keep payments manageable. Additionally, after 20-25 years of qualifying payments, any remaining loan balance may be eligible for forgiveness. \n",
        "\n",
        "**3. Key Benefits:**\n",
        "   - **Lower Payments**: IBR plans decrease the monthly payment amount, making it easier for low-income students to manage their loans successfully.\n",
        "   - **Forgiveness Opportunities**: Those who pursue careers in public service may qualify for further loan forgiveness options.\n",
        "\n",
        "**4. The Importance of Financial Aid Awareness:**\n",
        "It is vital for low-income students to be aware of their options concerning financial aid and student loans. We recommend that students and families familiarize themselves with the array of resources available, such as [Federal Student Aid](https://studentaid.gov), which provides comprehensive information on eligibility and application processes.\n",
        "\n",
        "If you need further assistance or have specific questions, please don’t hesitate to reach out. Our goal is to ensure that every student can pursue their educational aspirations without the fear of overwhelming debt.\n",
        "\n",
        "Best regards,\n",
        "\n",
        "[Your Name]  \n",
        "[Your Position]  \n",
        "[Your Contact Information]  \n",
        "[Your Organization]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
